# Week4_Day2<br>
#南瓜数据集<br>
##1.首先，我发现日期信息在该数据集中参考价值有限。在数据清洗阶段，我直接删除了包含缺失值的行，而日期字段并未被我选为特征。<br>
##2.我选择了以下几个列名：<br>
###Item Size、Origin、Variety、City Name、Package、Low Price, High Price<br>
##3.样本分布特点：<br>
###数据清洗后保留了完整记录的样本，说明这些特征的样本量相对充足<br>
##同时，通过这次南瓜价格预测的建模实践，我学到了很多关于模型选择和特征处理的知识：<br>
###​​模型特性对比​​：<br>
####线性回归(LR)模型训练速度非常快，但预测效果明显不如随机森林(RF)，这让我直观理解了线性模型对特征线性关系的强假设限制。当特征与价格之间可能存在复杂非线性关系时，LR的表现就会受限。<br>
###​​编码方式的影响​​：<br>
####在RF模型中，OneHot编码和Ordinal编码效果相近，但在LR模型中差异较大。这说明树模型对编码方式不敏感，因为它可以自动学习特征分割，而线性模型则严重依赖特征表达方式。<br>
<br>
#特征处理<br>
##1.​​特征编码方式的影响​​<br>
###​​线性回归对编码方式非常敏感。使用Ordinal编码时，模型会误认为类别数字的大小关系有意义，导致预测偏差。而OneHot编码消除了这种虚假的顺序关系，使LR表现更好。<br>
###​​随机森林对编码方式的敏感度较低，因为树模型可以自动学习最佳分割点。但实验发现，OneHot编码在RF上的表现仍然略好，可能是因为它能更清晰地表示类别间的独立关系。<br>
​​##2.多重共线性的影响​​<br>
###​​虽然没画热力图，但从数据中可以推测，某些特征可能存在相关性。<br>
###​​线性回归容易受多重共线性影响，导致系数不稳定，但随机森林不受影响，因为它不依赖特征的线性组合。<br>
​​##3.时间特征的取舍​​<br>
###​​原始数据可能包含日期信息，但实验中直接删除了。这是因为南瓜价格可能主要受品种、产地等静态因素影响，而非时间趋势，并且​​如果样本时间跨度不足，时间特征可能反而引入噪声。<br>
###​​不过，如果数据包含完整的年度周期，加入月份特征可能会捕捉季节性规律，值得后续尝试。<br>
##4.​​特征重要性的观察​​<br>
###​​随机森林的feature_importances_显示，"品种"和"产地"对价格预测贡献最大，而"包装方式"影响较小。<br>
###​​这说明特征选择很重要——如果某些特征几乎不影响预测，可以考虑剔除以简化模型。<br>
<br>
#模型<br>
##树模型的深度与复杂度控制​​<br>
###在使用LGBM和XGBoost时，我发现max_depth参数对模型性能影响很大<br>
###num_leaves参数也类似，设置过大会导致模型记住噪声，而合理值能保持较好泛化能力<br>
​​##学习率与迭代次数的权衡​​<br>
###通过调整learning_rate和n_estimators发现：<br>
###小学习率需要更多迭代才能收敛，但最终模型更稳定<br>
###大学习率训练快，但容易错过最优解，需要配合早停机制<br>
###最终采用learning_rate=0.1 + early_stopping_rounds=50的组合，既保证效率又防止过拟合<br>
##​​模型从数据中学到的规律​​<br>
###通过feature_importance分析发现：<br>
###温度相关特征对能耗预测最重要，这与物理常识一致<br>
###时间特征中"小时"比"月份"更重要，说明日内用电模式比季节性变化更显著<br>
###线性模型学到的系数显示：<br>
###温度与能耗呈正相关<br>
###非工作时间段的能耗基线明显较低<br>
##​​不同模型的特性对比​​<br>
###线性回归：<br>
###训练速度极快<br>
###但对非线性关系捕捉不足，R²比树模型低20%左右<br>
###树模型：<br>
###能自动发现特征交互<br>
###但需要仔细调参避免过拟合<br>
